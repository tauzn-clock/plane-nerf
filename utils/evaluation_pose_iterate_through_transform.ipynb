{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation \n",
    "from IPython.display import clear_output\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from inerf.inerf_trainer import load_data_into_trainer\n",
    "from inerf.inerf_utils import get_corrected_pose, load_eval_image_into_pipeline, get_relative_pose, get_absolute_diff_for_pose, get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace')\n",
    "MODEL_PATH = \"/workspace/outputs/jackal_with_box/plane-nerf-simplified/2024-02-13_163941\"\n",
    "DATA_PATH = \"/stored_data/jackal_with_box_eval/\"\n",
    "GROUND_TRUTH_PATH = os.path.join(DATA_PATH, \"ground_truth.json\")\n",
    "TRANSFORM_FILE = \"transforms_10.json\"\n",
    "with open(GROUND_TRUTH_PATH) as f:\n",
    "    GROUND_TRUTH = json.load(f)\n",
    "with open(os.path.join(DATA_PATH, TRANSFORM_FILE)) as f:\n",
    "    TRANSFORM = json.load(f)\n",
    "SAVE_FILE_NAME = \"eval_results_\"+str(time.strftime(\"%Y-%m-%d_%H%M%S\"))+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n",
      "Warning: FullyFusedMLP is not supported for the selected architecture 37. Falling back to CutlassMLP. For maximum performance, raise the target GPU architecture to 75+.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from \n",
       "outputs/jackal_with_box/plane-nerf-simplified/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-13_163941/nerfstudio_models/step-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000009999.</span>ckpt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Done loading checkpoint from \n",
       "outputs/jackal_with_box/plane-nerf-simplified/\u001b[1;36m2024\u001b[0m-\u001b[1;36m02\u001b[0m-13_163941/nerfstudio_models/step-\u001b[1;36m000009999.\u001b[0mckpt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_path = os.path.join(MODEL_PATH, \"config.yml\")\n",
    "config, pipeline, _, _ = eval_setup(\n",
    "                        Path(config_path),\n",
    "                        test_mode=\"inference\",\n",
    "                        )\n",
    "config.pipeline.datamanager.pixel_sampler.num_rays_per_batch = 4096 \n",
    "\n",
    "train_loop = 10\n",
    "n = 100\n",
    "lr_max = 5e-3\n",
    "lr_min = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Number of keypoints:  49\n",
      "Number of rays:  2326\n",
      "Randomly select more rays\n",
      "Final number of rays:  4096\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for f in range(len(TRANSFORM[\"frames\"])):\n",
    "    transform = TRANSFORM.copy()\n",
    "    transform[\"frames\"] = [TRANSFORM[\"frames\"][f]]\n",
    "    \n",
    "    tf = GROUND_TRUTH[\"frames\"][f][\"transform_matrix\"]\n",
    "    tf = np.asarray(tf)\n",
    "    tf = tf[:3, :4 ]\n",
    "    ground_truth_poses = [tf]\n",
    "    ground_truth_poses = torch.tensor(ground_truth_poses).to(pipeline.device)\n",
    "    \n",
    "    pipeline = load_eval_image_into_pipeline(pipeline,DATA_PATH,transform)\n",
    "\n",
    "    config.pipeline.datamanager.pixel_sampler.num_rays_per_batch = 4096 \n",
    "\n",
    "    trainer = load_data_into_trainer(\n",
    "        config,\n",
    "        pipeline,\n",
    "        plane_optimizer = False\n",
    "    )\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f)\n",
    "    \n",
    "    trainer.pipeline.datamanager.KERNEL_SIZE = 5\n",
    "    trainer.pipeline.datamanager.THRESHOLD = 5\n",
    "    trainer.pipeline.datamanager.METHOD = \"sift\"\n",
    "    trainer.pipeline.datamanager.get_inerf_batch()  \n",
    "        \n",
    "    store = torch.tensor([])\n",
    "\n",
    "    corrected_pose = get_corrected_pose(trainer)\n",
    "\n",
    "    relative_pose = get_relative_pose(ground_truth_poses, corrected_pose)\n",
    "    t_diff, r_diff = get_absolute_diff_for_pose(relative_pose)\n",
    "\n",
    "    store = torch.cat((store, torch.tensor([torch.mean(t_diff), torch.mean(r_diff)])), 0)\n",
    "\n",
    "    for i in range(train_loop):\n",
    "        for j in range(n):\n",
    "            lr = lr_min + (lr_max - lr_min) * (i / train_loop)\n",
    "            trainer.pipeline.train()\n",
    "            loss = trainer.train_iteration_inerf(i*n + j,optimizer_lr = 1e-3)\n",
    "        corrected_pose = get_corrected_pose(trainer)\n",
    "\n",
    "        relative_pose = get_relative_pose(ground_truth_poses, corrected_pose)\n",
    "        t_diff, r_diff = get_absolute_diff_for_pose(relative_pose)\n",
    "\n",
    "        store = torch.cat((store, torch.tensor([torch.mean(t_diff), torch.mean(r_diff)])), 0)\n",
    "    \n",
    "    output.append(store.to(\"cpu\").numpy().tolist())\n",
    "    np.savetxt(os.path.join(MODEL_PATH,SAVE_FILE_NAME), np.asarray(output), delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
